---
title: "Simulate data with Jags"
author: "Olivier Gimenez, November 21 2017"
output:
  pdf_document: default
  html_document: default
---

## Motivation

Recently, I have been struggling with simulating data from complex hierarchical models. After several unsuccessful attempts in `R`, I remembered the good old times when I was using `WinBUGS` (more than 10 years already!) and the possibility to simulate data with it. I'm using `Jags` now, and a quick search in Google with 'simulating data with jags' led me to [a complex example](https://www.georg-hosoya.de/wordpress/?p=799) and [a simple example](https://stackoverflow.com/questions/38295839/simulate-data-in-jags-r2jags).

Here, I illustrate the possibility to use Jags to simulate data with two examples that might be of interest to population ecologists: first a linear regression, second a Cormack-Jolly-Seber capture-recapture model to estimate animal survival (formulated as a state-space model). 

Simulating data with `Jags` is convenient because you can use (almost) the same code for simulation and inference, and you can carry out simulation studies (bias, precision, interval coverage) in the same environment (namely `Jags`). 

## Linear regression example

We first load the packages we will need for this tutorial:
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(R2jags)
library(runjags)
library(mcmcplots)
```

Then straight to the point, let's generate data from a linear regression model. The trick is to use a `data` block, have the simplest `model` block you could think of and pass the parameters as if they were data. Note that it'd be possible to use only a model block, see comment [here](https://stackoverflow.com/questions/38295839/simulate-data-in-jags-r2jags).
```{r}
txtstring <- '
data{
# Likelihood:
for (i in 1:N){
y[i] ~ dnorm(mu[i], tau) # tau is precision (1 / variance)
mu[i] <- alpha + beta * x[i]
}
}
model{
fake <- 0
}
'
```

Here, `alpha` and `beta` are the intercept and slope, `tau` the precision or the inverse of the variance, `y` the response variable and `x` the explanatory variable.

We pick some values for the model parameters that we will use as data:
```{r}
# parameters for simulations 
N = 30 # nb of observations
x <- 1:N # predictor
alpha = 0.5 # intercept
beta = 1 # slope
sigma <- .1 # residual sd
tau <- 1/(sigma*sigma) # precision
# parameters are treated as data for the simulation step
data<-list(N=N,x=x,alpha=alpha,beta=beta,tau=tau)
```

Now call jags; note that we monitor the response variable instead of parameters as we would do when conducting standard inference:
```{r}
# run jags
out <- run.jags(txtstring, data = data,monitor=c("y"),sample=1, n.chains=1, summarise=FALSE)
```

The output is a bit messy and needs to be formated appropriately:
```{r}
# reformat the outputs
Simulated <- coda::as.mcmc(out)
Simulated
dim(Simulated)
dat = as.vector(Simulated)
dat
```

Now let's fit the model we used to simulate to the data we just generated. I won't go into the details and assume that the reader is familiar with `Jags` and linear regression.
```{r}
# specify model in BUGS language
model <- 	
paste("	
model {
# Likelihood:
for (i in 1:N){
y[i] ~ dnorm(mu[i], tau) # tau is precision (1 / variance)
mu[i] <- alpha + beta * x[i]
}
# Priors:
alpha ~ dnorm(0, 0.01) # intercept
beta ~ dnorm(0, 0.01) # slope
sigma ~ dunif(0, 100) # standard deviation
tau <- 1 / (sigma * sigma) 
}
")
writeLines(model,"lin_reg.jags")	

# data
jags.data <- list(y = dat, N = length(dat), x = x)

# initial values
inits <- function(){list(alpha = rnorm(1), beta = rnorm(1), sigma = runif(1,0,10))}  

# parameters monitored
parameters <- c("alpha", "beta", "sigma")

# MCMC settings
ni <- 10000
nt <- 6
nb <- 5000
nc <- 2

# call JAGS from R
res <- jags(jags.data, inits, parameters, "lin_reg.jags", n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb, working.directory = getwd())
```

Let's have a look to the results and compare with the parameters we used to simulate the data (see above):
```{r}
# summarize posteriors
print(res, digits = 3)
```

Pretty close! 

Check convergence:
```{r}
# trace plots
traplot(res,c("alpha", "beta", "sigma"))
```

Plot the posterior distribution of the regression parameters and residual standard deviation:
```{r}
# posterior distributions
denplot(res,c("alpha", "beta", "sigma"))
```

## Capture-recapture example

I now illustrate the use of `Jags` to simulate data from a Cormack-Jolly-Seber model with constant survival and recapture probabilities. I assume that the reader is familiar with this model and its formulation as a state-space model.

Let's simulate!
```{r}
txtstring <- '
data{
# Constant survival and recapture probabilities
for (i in 1:nind){
   for (t in f[i]:(n.occasions-1)){
      phi[i,t] <- mean.phi
      p[i,t] <- mean.p
      } #t
   } #i
# Likelihood 
for (i in 1:nind){
   # Define latent state and obs at first capture
   z[i,f[i]] <- 1
   mu2[i,1] <- 1 * z[i,f[i]] # detection is 1 at first capture ("conditional on first capture")
   y[i,1] ~ dbern(mu2[i,1])
   # then deal w/ subsequent occasions
   for (t in (f[i]+1):n.occasions){
      # State process
      z[i,t] ~ dbern(mu1[i,t])
      mu1[i,t] <- phi[i,t-1] * z[i,t-1]
      # Observation process
      y[i,t] ~ dbern(mu2[i,t])
      mu2[i,t] <- p[i,t-1] * z[i,t]
      } #t
   } #i
}
model{
fake <- 0
}
'
```

Let's pick some values for parameters and store them in a data list:
```{r}
# parameter for simulations 
n.occasions = 10 # nb of occasions
nind = 100 # nb of individuals
mean.phi <- 0.8 # survival
mean.p <- 0.6 # recapture
f = rep(1,nind) # date of first capture
data<-list(n.occasions = n.occasions, mean.phi = mean.phi, mean.p = mean.p, f = f, nind = nind)
```

Now run `Jags`:
```{r}
out <- run.jags(txtstring, data = data,monitor=c("y"),sample=1, n.chains=1, summarise=FALSE)
```

Format the output:
```{r}
Simulated <- coda::as.mcmc(out)
dim(Simulated)
dat = matrix(Simulated,nrow=nind)
head(dat)
```

Here I monitored only the detections and non-detections, but it is also possible to get the simulated values for the states, i.e. whether an individual is alive or dead at each occasion. You just need to amend the call to `Jags` with `monitor=c("y","x")` and to amend the output accordingly. 

Now we fit a Cormack-Jolly-Seber model to the data we've just simulated, assuming constant parameters:
```{r}
model <- 	
paste("	
model {
# Priors and constraints
for (i in 1:nind){
   for (t in f[i]:(n.occasions-1)){
      phi[i,t] <- mean.phi
      p[i,t] <- mean.p
      } #t
   } #i
mean.phi ~ dunif(0, 1)         # Prior for mean survival
mean.p ~ dunif(0, 1)           # Prior for mean recapture
# Likelihood 
for (i in 1:nind){
   # Define latent state at first capture
   z[i,f[i]] <- 1
   for (t in (f[i]+1):n.occasions){
      # State process
      z[i,t] ~ dbern(mu1[i,t])
      mu1[i,t] <- phi[i,t-1] * z[i,t-1]
      # Observation process
      y[i,t] ~ dbern(mu2[i,t])
      mu2[i,t] <- p[i,t-1] * z[i,t]
      } #t
   } #i
}
")
writeLines(model,"cjs.jags")	
```

Prepare the data:
```{r}
# vector with occasion of marking
get.first <- function(x) min(which(x!=0))
f <- apply(dat, 1, get.first)
# data
jags.data <- list(y = dat, f = f, nind = dim(dat)[1], n.occasions = dim(dat)[2])
```

```{r}
# Initial values
known.state.cjs <- function(ch){
   state <- ch
   for (i in 1:dim(ch)[1]){
      n1 <- min(which(ch[i,]==1))
      n2 <- max(which(ch[i,]==1))
      state[i,n1:n2] <- 1
      state[i,n1] <- NA
      }
   state[state==0] <- NA
   return(state)
   }
inits <- function(){list(mean.phi = runif(1, 0, 1), mean.p = runif(1, 0, 1), z = known.state.cjs(dat))}
```

We'd like to carry out inference about survival and recapture probabilities:
```{r}
parameters <- c("mean.phi", "mean.p")
```

Standard MCMC settings:
```{r}
ni <- 10000
nt <- 6
nb <- 5000
nc <- 2
```

Ready to run `Jags`!
```{r}
# Call JAGS from R (BRT 1 min)
cjs <- jags(jags.data, inits, parameters, "cjs.jags", n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb, working.directory = getwd())
```

Summarize posteriors and compare to the values we used to simulate the data:
```{r}
print(cjs, digits = 3)
```

Again pretty close!

Trace plots
```{r}
traplot(cjs,c("mean.phi", "mean.p"))
```

Posterior distribution plots:
```{r}
denplot(cjs,c("mean.phi", "mean.p"))
```
